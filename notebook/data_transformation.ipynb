{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "import random\n",
    "sys.path.append(\"../\") # go to parent dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root_dir = '../data/ODIR-5K_Training_Images/ODIR-5K_Training_Dataset'\n",
    "img_paths = glob(f'{data_root_dir}/*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected_img_paths = random.sample(img_paths, 10)\n",
    "\n",
    "# # Display the selected images\n",
    "# for img_path in selected_img_paths:\n",
    "#     img = plt.imread(img_path)\n",
    "#     plt.imshow(img)\n",
    "#     plt.axis('off')\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dell\\Desktop\\0pthalmogy_dataset\\opthalmology_project\\venv\\Lib\\site-packages\\torchvision\\transforms\\v2\\_deprecated.py:43: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from torchvision.transforms import v2\n",
    "transforms=v2.Compose([\n",
    "    v2.Resize(size=(256, 256)),\n",
    "    v2.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "def crop_nonzero(image_path, output_path):\n",
    "   \n",
    "    image = Image.open(image_path)\n",
    "    bbox = image.getbbox()\n",
    "    cropped_image = image.crop(bbox)\n",
    "    cropped_image.save(output_path)\n",
    "input_folder = '../data/ODIR-5K_Training_Images/ODIR-5K_Training_Dataset'\n",
    "output_folder = '../data/cropped_images_folder'\n",
    "\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.endswith(('.jpg')):\n",
    "        input_path = os.path.join(input_folder, filename)\n",
    "        output_path = os.path.join(output_folder, filename)\n",
    "        crop_nonzero(input_path, output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for image_path in img_paths:\n",
    "#     fig,ax = plt.subplots(1,2)\n",
    "#     original_image = Image.open(img_path)\n",
    "#     transformed_image = transforms(original_image)\n",
    "#     ax[0].imshow(original_image)\n",
    "#     transformed_image_np = transformed_image.numpy().transpose(1, 2, 0)\n",
    "#     ax[1].imshow(transformed_image_np)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '0_left.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m g_mean_sum\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[0;32m      7\u001b[0m g_std_sum\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimage_dataset\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimg_np\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mg_mean_sum\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimg_np\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Dell\\Desktop\\0pthalmogy_dataset\\opthalmology_project\\notebook\\..\\src\\datasets.py:34\u001b[0m, in \u001b[0;36mODRDataset.__getitem__\u001b[1;34m(self, label)\u001b[0m\n\u001b[0;32m     31\u001b[0m image_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimages[label]\n\u001b[0;32m     32\u001b[0m label\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels[label]\n\u001b[1;32m---> 34\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[0;32m     37\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms(image)\n",
      "File \u001b[1;32mc:\\Users\\Dell\\Desktop\\0pthalmogy_dataset\\opthalmology_project\\venv\\Lib\\site-packages\\PIL\\Image.py:3247\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   3244\u001b[0m     filename \u001b[38;5;241m=\u001b[39m fp\n\u001b[0;32m   3246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename:\n\u001b[1;32m-> 3247\u001b[0m     fp \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3248\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   3250\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '0_left.jpg'"
     ]
    }
   ],
   "source": [
    "from src.datasets import ODRDataset\n",
    "import numpy as np\n",
    "\n",
    "image_dataset=ODRDataset(csv_path=\"../data/processed_train_ODIR-5K.csv\",transforms=None)\n",
    "\n",
    "g_mean_sum=0\n",
    "g_std_sum=0\n",
    "for img,_ in image_dataset:\n",
    "    img_np=np.array(img)\n",
    "    g_mean_sum+=img_np[2].mean()\n",
    "    g_std_sum+=img_np.std()\n",
    "    \n",
    "#print(r_mean_sum/len(image_dataset),r_std_sum/len(image_dataset))\n",
    "print(g_mean_sum/len(image_dataset),g_std_sum/len(image_dataset))\n",
    "#print(b_mean_sum/len(image_dataset),b_std_sum/len(image_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
